#!/usr/bin/env python
# ==========================================================
#  evaluate_gt_matching_v2.py - GT ë°ì´í„°ë¡œ ì¶”ë¡  ì •í™•ë„ í‰ê°€ (OpenAI ì„ë² ë”©)
# ==========================================================
"""
GT í´ë”ì˜ ì´ë¯¸ì§€ì™€ JSONì„ ì‚¬ìš©í•˜ì—¬:
1. JSONì—ì„œ ì¢Œí‘œë¡œ ì´ë¯¸ì§€ í¬ë¡­
2. í¬ë¡­ëœ ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ë¡  (MMOCR íŒŒì´í”„ë¼ì¸ ì‚¬ìš©)
3. OpenAIë¡œ í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”© ë²¡í„°ë¡œ ë³€í™˜
4. Milvusì—ì„œ ìœ ì‚¬ ì±… ê²€ìƒ‰ (ì„ë² ë”© ë²¡í„° ì‚¬ìš©)
5. ì¶”ë¡  ê²°ê³¼ì™€ GT labelì„ ë¹„êµí•˜ì—¬ ì •í™•ë„ í‰ê°€
"""
import argparse
import json
from pathlib import Path
import sys
import torch
import numpy as np
from PIL import Image
from typing import List, Dict, Tuple
import re
import os
from mmengine.config import Config
from mmengine.runner import load_checkpoint
from mmengine.registry import init_default_scope, MODELS
from mmocr.utils import register_all_modules
from pymilvus import MilvusClient
from openai import OpenAI

# Compose import (êµ¬ë²„ì „ ìš°ì„ )
try:
    from mmocr.datasets.pipelines.compose import Compose
except ImportError:
    from mmcv.transforms import Compose


# ============================================================
# 1. ì´ë¯¸ì§€ í¬ë¡­ ê´€ë ¨
# ============================================================
def get_bbox_from_points(points: List[List[float]]) -> Tuple[int, int, int, int]:
    """
    pointsì—ì„œ bounding box ì¢Œí‘œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    rectangleì€ 2ê°œ í¬ì¸íŠ¸, polygonì€ 4ê°œ í¬ì¸íŠ¸

    Returns:
        (x_min, y_min, x_max, y_max)
    """
    points_array = np.array(points)
    x_min = int(points_array[:, 0].min())
    y_min = int(points_array[:, 1].min())
    x_max = int(points_array[:, 0].max())
    y_max = int(points_array[:, 1].max())

    return x_min, y_min, x_max, y_max


def crop_image_from_shape(image_path: Path, shape: Dict, padding: int = 5) -> Image.Image:
    """
    JSON shape ì •ë³´ë¡œ ì´ë¯¸ì§€ë¥¼ í¬ë¡­í•©ë‹ˆë‹¤. (ì›ë³¸ ì‚¬ì´ì¦ˆ ìœ ì§€)

    Args:
        image_path: ì´ë¯¸ì§€ ê²½ë¡œ
        shape: shape ì •ë³´ (ì¢Œí‘œ í¬í•¨)
        padding: í¬ë¡­ ì˜ì—­ ì£¼ë³€ì— ì¶”ê°€í•  íŒ¨ë”© (í”½ì…€)
    """
    try:
        img = Image.open(image_path)
        img_width, img_height = img.size

        x_min, y_min, x_max, y_max = get_bbox_from_points(shape['points'])

        # íŒ¨ë”© ì¶”ê°€ (ì´ë¯¸ì§€ ê²½ê³„ë¥¼ ë²—ì–´ë‚˜ì§€ ì•Šë„ë¡)
        x_min = max(0, x_min - padding)
        y_min = max(0, y_min - padding)
        x_max = min(img_width, x_max + padding)
        y_max = min(img_height, y_max + padding)

        # ì´ë¯¸ì§€ í¬ë¡­ (ì›ë³¸ ì‚¬ì´ì¦ˆ)
        cropped = img.crop((x_min, y_min, x_max, y_max))
        return cropped
    except Exception as e:
        print(f"âš ï¸ ì´ë¯¸ì§€ í¬ë¡­ ì˜¤ë¥˜ ({image_path.name}): {e}")
        return None

# ============================================================
# 2. MMOCR ëª¨ë¸ ë¡œë“œ ë° ì¶”ë¡ 
# ============================================================
def build_model_and_pipeline(cfg_path: Path,
                             ckpt_path: Path,
                             device: str = 'cpu'):
    """MMOCR ëª¨ë¸ê³¼ ì¶”ë¡  íŒŒì´í”„ë¼ì¸ ì„¤ì •ì„ ë¹Œë“œí•©ë‹ˆë‹¤."""
    try:
        cfg = Config.fromfile(str(cfg_path))

        # pretrained / init_cfg ì œê±°
        for k in ('pretrained', 'init_cfg'):
            cfg.model.pop(k, None)
            if isinstance(cfg.model.get('backbone'), dict):
                cfg.model.backbone.pop(k, None)

        # ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì´ˆê¸°í™”
        init_default_scope(cfg.default_scope)
        register_all_modules()

        # ëª¨ë¸ ìƒì„± + checkpoint ë¡œë“œ
        model = MODELS.build(cfg.model)
        load_checkpoint(model, str(ckpt_path), map_location=device)
        model.to(device).eval()

        # inference ì „ìš© íŒŒì´í”„ë¼ì¸ ì„¤ì • ê°€ì ¸ì˜¤ê¸°
        orig_pipeline = (cfg.get('test_pipeline')
                         or cfg.test_dataloader.dataset.pipeline)

        # annotationì„ ìš”êµ¬í•˜ëŠ” ë³€í™˜ ì œê±°
        inference_pipeline_cfg = [
            t for t in orig_pipeline
            if 'Annotation' not in t['type'] and 'Label' not in t['type']
        ]

        return model, inference_pipeline_cfg
    except Exception as e:
        sys.exit(f"âŒ ëª¨ë¸ ë˜ëŠ” íŒŒì´í”„ë¼ì¸ ë¹Œë“œ ì‹¤íŒ¨: {e}")


@torch.inference_mode()
def infer_text_from_image(model, pipeline_cfg: List[Dict], img_path: Path) -> str:
    """
    ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ë°›ì•„ MMOCR íŒŒì´í”„ë¼ì¸ì„ ì ìš©í•˜ê³  í…ìŠ¤íŠ¸ë¥¼ ì¶”ë¡ í•©ë‹ˆë‹¤.
    pipeline_cfgëŠ” Compose ê°ì²´ê°€ ì•„ë‹Œ ì„¤ì • ë¦¬ìŠ¤íŠ¸ì—¬ì•¼ í•©ë‹ˆë‹¤.
    """
    try:
        # Compose ê°ì²´ë¥¼ í•¨ìˆ˜ ë‚´ì—ì„œ ìƒì„±
        pipeline = Compose(pipeline_cfg)

        # ì´ë¯¸ì§€ ê²½ë¡œë§Œ ì „ë‹¬, íŒŒì´í”„ë¼ì¸ì´ LoadImageFromFileë¶€í„° ì²˜ë¦¬
        # img_shapeì€ íŒŒì´í”„ë¼ì¸ ë‚´ì—ì„œ ë¡œë“œëœ ì´ë¯¸ì§€ë¡œë¶€í„° ì–»ì–´ì§€ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ë¶ˆí•„ìš”
        data = dict(img_path=str(img_path))
        data = pipeline(data)

        # ë°°ì¹˜ í˜•íƒœë¡œ ê°ì‹¸ê¸°
        inputs_key = 'imgs' if 'imgs' in data else 'inputs'
        batch_data = {
            inputs_key: [data[inputs_key]],
            'data_samples': [data['data_samples']]
        }

        pred_sample = model.test_step(batch_data)[0]

        # pred_text ì¶”ì¶œ (ì—¬ëŸ¬ ê°€ëŠ¥í•œ í˜•ì‹ ì²˜ë¦¬)
        pred_text_obj = pred_sample.pred_text

        # MMOCR ë²„ì „ì— ë”°ë¥¸ pred_text ì¶”ì¶œ ë°©ì‹ ë¶„ê¸°
        if hasattr(pred_text_obj, 'item'):  # ì˜ˆ: LabelData ê°ì²´
             pred_text = pred_text_obj.item
        elif isinstance(pred_text_obj, dict) and 'text' in pred_text_obj:
             pred_text = pred_text_obj['text']
        elif isinstance(pred_text_obj, str):
             pred_text = pred_text_obj
        else:
             pred_text = str(pred_text_obj)

        # OCR ê²°ê³¼ í›„ì²˜ë¦¬
        pred_text = normalize_text_for_ocr(parse_item_text(pred_text))

        return pred_text
    except FileNotFoundError:
        print(f"    âš ï¸ OCR ì˜¤ë¥˜: íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ - {img_path}")
        return ""
    except Exception as e:
        print(f"    âš ï¸ OCR ì¶”ë¡  ì¤‘ ì˜ˆì™¸ ë°œìƒ ({img_path.name}): {e}")
        return ""


# ============================================================
# 3. OpenAI ì„ë² ë”© ìƒì„±
# ============================================================
class OpenAIEmbedder:
    """OpenAI APIë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”© ë²¡í„°ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""

    def __init__(self, api_key: str = None, model: str = "text-embedding-3-large"):
        """
        Args:
            api_key: OpenAI API í‚¤ (Noneì´ë©´ í™˜ê²½ë³€ìˆ˜ì—ì„œ ì½ìŒ)
            model: ì‚¬ìš©í•  ì„ë² ë”© ëª¨ë¸
        """
        self.model = model

        # Initialize OpenAI client (simple initialization like the working example)
        if api_key:
            self.client = OpenAI(api_key=api_key)
        else:
            # Use default (reads from OPENAI_API_KEY env var)
            self.client = OpenAI()

    def embed_text(self, text: str, max_retries: int = 3) -> np.ndarray:
        """
        í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”© ë²¡í„°ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

        Args:
            text: ì„ë² ë”©í•  í…ìŠ¤íŠ¸
            max_retries: ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜

        Returns:
            ì„ë² ë”© ë²¡í„° (numpy array)
        """
        if not text or not text.strip():
            # ë¹ˆ í…ìŠ¤íŠ¸ëŠ” zero ë²¡í„° ë°˜í™˜
            return np.zeros(3072)  # text-embedding-3-large ì°¨ì›

        for retry in range(max_retries):
            try:
                response = self.client.embeddings.create(
                    model=self.model,
                    input=text,
                    timeout=60.0
                )

                embedding = response.data[0].embedding
                return np.array(embedding, dtype=np.float32)

            except Exception as e:
                if retry < max_retries - 1:
                    wait_time = (2 ** retry) * 1.0  # 1s, 2s, 4s
                    print(f"    âš ï¸ OpenAI API ì˜¤ë¥˜ (ì¬ì‹œë„ {retry + 1}/{max_retries}): {e}")
                    import time
                    time.sleep(wait_time)
                else:
                    print(f"    âŒ OpenAI API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
                    # ì‹¤íŒ¨ ì‹œ zero ë²¡í„° ë°˜í™˜
                    return np.zeros(3072)

        return np.zeros(3072)


# ============================================================
# 4. Milvus ê²€ìƒ‰ (ì„ë² ë”© ë²¡í„° ì‚¬ìš©)
# ============================================================
def search_in_milvus(
    query_embedding: np.ndarray,
    collection_name: str = "domestic_book_meta_embedding",
    milvus_uri: str = "http://10.10.13.129:19530",
    search_field: str = "itemTitle_embedding",
    limit: int = 5
):
    """
    Milvusì—ì„œ ìœ ì‚¬ë„ ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

    Args:
        query_embedding: ê²€ìƒ‰í•  ì„ë² ë”© ë²¡í„° (numpy array)
        collection_name: Milvus ì»¬ë ‰ì…˜ ì´ë¦„
        milvus_uri: Milvus ì„œë²„ URI
        search_field: ê²€ìƒ‰í•  ì„ë² ë”© í•„ë“œ
        limit: ë°˜í™˜í•  ìµœëŒ€ ê²°ê³¼ ìˆ˜
    """
    # ì„ë² ë”©ì´ ë¹„ì–´ìˆê±°ë‚˜ zero ë²¡í„°ë©´ ê²€ìƒ‰ ê±´ë„ˆëœ€
    if query_embedding is None or np.all(query_embedding == 0):
        print("    âš ï¸ Milvus ê²€ìƒ‰ ê±´ë„ˆëœ€ (ì„ë² ë”© ë²¡í„° ì—†ìŒ)")
        return None

    try:
        client = MilvusClient(uri=milvus_uri)

        # ì„ë² ë”© ë²¡í„°ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        query_vector = query_embedding.tolist()

        results = client.search(
            collection_name=collection_name,
            data=[query_vector],  # âœ… ì„ë² ë”© ë²¡í„° ì „ë‹¬
            anns_field=search_field,
            limit=limit,
            output_fields=[
                "itemId",
                "itemTitle",
                "itemSubTitle",
                "authorName",
            ]
        )

        # ê²°ê³¼ êµ¬ì¡° í™•ì¸
        if results and results[0]:
             # score ëŒ€ì‹  distance ì‚¬ìš© í™•ì¸
             if isinstance(results[0][0].get('score'), float):
                  dist_key = 'score'
             else:
                  dist_key = 'distance'

             # entity êµ¬ì¡° í™•ì¸
             if 'entity' in results[0][0]:
                  entity_key = 'entity'
             else:
                  entity_key = None

             parsed_results = []
             for hit in results[0]:
                  entity_data = hit.get(entity_key) if entity_key else hit
                  parsed_results.append({
                       'id': hit['id'],
                       'distance': float(hit[dist_key]),
                       'entity': entity_data if entity_data else {}
                  })
             return [parsed_results]
        else:
             return None

    except Exception as e:
        print(f"    âš ï¸ Milvus ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        return None


# ============================================================
# 5. OCR ê²°ê³¼ í›„ì²˜ë¦¬
# ============================================================
def parse_item_text(text_str):
    """Parse dict-string format: "{'item': 'text', 'score': [...]}" """
    text_str = str(text_str)
    if text_str.startswith('{') and "'item':" in text_str:
        try:
            import ast
            parsed = ast.literal_eval(text_str)
            if isinstance(parsed, dict) and 'item' in parsed:
                return str(parsed['item'])
        except:
            pass
    return text_str


def normalize_text_for_ocr(text_str):
    """Remove special tokens and normalize whitespace for OCR output."""
    text_str = str(text_str)

    # Remove special tokens
    special_tokens = ['<UNK>', '<BOS>', '<EOS>', '<PAD>', '<unk>', '<bos>', '<eos>', '<pad>']
    for token in special_tokens:
        text_str = text_str.replace(token, ' ')

    # Normalize whitespace
    text_str = re.sub(r'\s+', ' ', text_str).strip()

    return text_str


# ============================================================
# 6. í‰ê°€ìš© í…ìŠ¤íŠ¸ ì •ê·œí™”
# ============================================================
def normalize_text(text: str) -> str:
    """í…ìŠ¤íŠ¸ ì •ê·œí™” (ê³µë°±, íŠ¹ìˆ˜ë¬¸ì ì œê±°) - í‰ê°€ìš©"""
    # ê³µë°± ì œê±°
    text = re.sub(r'\s+', '', text)
    return text.lower()


def check_match(predicted: str, ground_truth: str, top_results: list) -> Dict:
    """
    ì˜ˆì¸¡ ê²°ê³¼ì™€ GTë¥¼ ë¹„êµí•˜ê³ , Milvus ê²€ìƒ‰ ê²°ê³¼ë„ í‰ê°€í•©ë‹ˆë‹¤.
    """
    pred_norm = normalize_text(predicted)
    gt_norm = normalize_text(ground_truth)

    # OCR ì •í™•ë„
    ocr_exact_match = (pred_norm == gt_norm)
    ocr_partial_match = (gt_norm in pred_norm) if pred_norm else False

    # Milvus ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì •ë‹µ ì°¾ê¸°
    milvus_match = False
    milvus_rank = None
    milvus_score = None
    search_results_info = []

    if top_results and top_results[0]:
        for rank, hit in enumerate(top_results[0], 1):
            entity = hit.get('entity', {})
            distance = hit.get('distance')
            title = entity.get('itemTitle', '')
            title_norm = normalize_text(title)

            is_match = (gt_norm in title_norm) if title_norm else False

            # ê²€ìƒ‰ ê²°ê³¼ ì •ë³´ ì €ì¥
            search_results_info.append({
                'rank': rank,
                'title': title,
                'score': distance,
                'is_match': is_match
            })

            # ì •ë‹µê³¼ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸
            if is_match and not milvus_match:
                milvus_match = True
                milvus_rank = rank
                milvus_score = distance

    return {
        'ocr_exact_match': ocr_exact_match,
        'ocr_partial_match': ocr_partial_match,
        'milvus_match': milvus_match,
        'milvus_rank': milvus_rank,
        'milvus_score': milvus_score,
        'top_results': search_results_info,
    }


# ============================================================
# 7. ë©”ì¸ í‰ê°€ í•¨ìˆ˜
# ============================================================
def evaluate_gt_data(
    gt_folder: Path,
    model,
    pipeline_cfg: List[Dict],
    embedder: OpenAIEmbedder,
    milvus_collection: str,
    milvus_uri: str,
    search_field: str,
    top_k: int = 5,
    temp_dir: Path = None,
    auto_confirm: bool = False,
    max_api_cost: float = 1.0
):
    """
    GT í´ë”ì˜ ëª¨ë“  ë°ì´í„°ë¥¼ í‰ê°€í•©ë‹ˆë‹¤.
    """

    if temp_dir is None:
        temp_dir = gt_folder / "temp_crops"
    temp_dir.mkdir(exist_ok=True)

    # JSON íŒŒì¼ ëª©ë¡
    json_files = sorted(gt_folder.glob("*.json"))

    if not json_files:
        print("âŒ JSON íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ì´ ìƒ˜í”Œ ìˆ˜ ê³„ì‚° (ë¹„ìš© ì¶”ì •ìš©)
    total_shapes = 0
    for json_file in json_files:
        try:
            with open(json_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                total_shapes += len(data.get('shapes', []))
        except:
            continue

    # API ë¹„ìš© ì¶”ì •
    # text-embedding-3-large: $0.00013 / 1K tokens
    # í‰ê·  í…ìŠ¤íŠ¸ ê¸¸ì´ë¥¼ 20 í† í°ìœ¼ë¡œ ê°€ì •
    estimated_tokens = total_shapes * 20
    estimated_cost = (estimated_tokens / 1000) * 0.00013

    print(f"\nğŸ“Š ì´ {len(json_files)}ê°œì˜ ì´ë¯¸ì§€, {total_shapes}ê°œì˜ ìƒ˜í”Œ í‰ê°€ ì˜ˆì •")
    print(f"ğŸ’° ì˜ˆìƒ API ë¹„ìš©: ${estimated_cost:.4f} (ì•½ {estimated_tokens:,} í† í°)")

    # ë¹„ìš© í™•ì¸
    if estimated_cost > max_api_cost:
        print(f"\nâš ï¸ ì˜ˆìƒ ë¹„ìš©(${estimated_cost:.4f})ì´ ìµœëŒ€ í—ˆìš© ë¹„ìš©(${max_api_cost:.2f})ì„ ì´ˆê³¼í•©ë‹ˆë‹¤.")
        print("--max-api-cost ì˜µì…˜ì„ ì¡°ì •í•˜ê±°ë‚˜ ë°ì´í„°ë¥¼ ì¤„ì—¬ì£¼ì„¸ìš”.")
        return

    if not auto_confirm and estimated_cost > 0.01:
        response = input(f"\nê³„ì† ì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ")
        if response.lower() != 'y':
            print("í‰ê°€ë¥¼ ì·¨ì†Œí–ˆìŠµë‹ˆë‹¤.")
            return

    print(f"\n{'='*80}")
    print("í‰ê°€ ì‹œì‘...")
    print(f"{'='*80}\n")

    total_shapes = 0
    ocr_exact_correct = 0
    ocr_partial_correct = 0
    milvus_correct = 0

    failed_embeddings = 0
    max_failed_embeddings = max(5, int(total_shapes * 0.1))  # ìµœëŒ€ 10% ì‹¤íŒ¨ í—ˆìš©

    detailed_results = []

    for json_file in json_files:
        # JSON ë¡œë“œ
        try:
            with open(json_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
        except json.JSONDecodeError:
            print(f"âš ï¸ JSON íŒŒì‹± ì˜¤ë¥˜: {json_file.name}")
            continue
        except Exception as e:
            print(f"âš ï¸ JSON ë¡œë“œ ì˜¤ë¥˜ ({json_file.name}): {e}")
            continue

        # ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
        image_path = gt_folder / data.get('imagePath', '')
        if not data.get('imagePath') or not image_path.exists():
            print(f"âš ï¸ ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ ëˆ„ë½ ë˜ëŠ” íŒŒì¼ ì—†ìŒ: {image_path}")
            continue

        print(f"\n{'='*80}")
        print(f"ğŸ“· ì²˜ë¦¬ ì¤‘: {image_path.name}")
        print(f"{'='*80}\n")

        # ê° shape ì²˜ë¦¬
        shapes = data.get('shapes', [])
        if not shapes:
            print(f"    âš ï¸ 'shapes' ì •ë³´ ì—†ìŒ: {json_file.name}")
            continue

        for idx, shape in enumerate(shapes):
            ground_truth = shape.get('label')
            if not ground_truth:
                print(f"    âš ï¸ shape {idx}: 'label' ì •ë³´ ì—†ìŒ")
                continue

            total_shapes += 1

            # 1. ì´ë¯¸ì§€ í¬ë¡­
            cropped_img = crop_image_from_shape(image_path, shape)
            if cropped_img is None:
                continue

            # 2. í¬ë¡­ëœ ì´ë¯¸ì§€ë¥¼ ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
            crop_path = temp_dir / f"{image_path.stem}_{idx}.jpg"
            try:
                # RGBA -> RGB ë³€í™˜
                if cropped_img.mode == 'RGBA':
                    background = Image.new('RGB', cropped_img.size, (255, 255, 255))
                    background.paste(cropped_img, mask=cropped_img.split()[3])
                    cropped_img = background
                elif cropped_img.mode != 'RGB':
                    cropped_img = cropped_img.convert('RGB')

                cropped_img.save(crop_path)
            except Exception as e:
                 print(f"    âš ï¸ ì„ì‹œ íŒŒì¼ ì €ì¥ ì˜¤ë¥˜ ({crop_path.name}): {e}")
                 continue

            # 3. OCR ì¶”ë¡ 
            predicted_text = infer_text_from_image(model, pipeline_cfg, crop_path)

            # 4. OpenAI ì„ë² ë”© ìƒì„±
            embedding = embedder.embed_text(predicted_text)

            # ì„ë² ë”© ì‹¤íŒ¨ ì²´í¬
            if np.all(embedding == 0) and predicted_text:  # í…ìŠ¤íŠ¸ëŠ” ìˆëŠ”ë° ì„ë² ë”©ì´ zero
                failed_embeddings += 1
                if failed_embeddings > max_failed_embeddings:
                    print(f"\nâŒ ì„ë² ë”© ì‹¤íŒ¨ íšŸìˆ˜ê°€ ë„ˆë¬´ ë§ìŠµë‹ˆë‹¤ ({failed_embeddings}íšŒ). í‰ê°€ë¥¼ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
                    break

            # 5. Milvus ê²€ìƒ‰
            search_results = search_in_milvus(
                embedding,
                collection_name=milvus_collection,
                milvus_uri=milvus_uri,
                search_field=search_field,
                limit=top_k
            )

            # 6. ì •í™•ë„ í‰ê°€
            match_result = check_match(predicted_text, ground_truth, search_results)

            # í†µê³„ ì—…ë°ì´íŠ¸
            if match_result['ocr_exact_match']:
                ocr_exact_correct += 1
            if match_result['ocr_partial_match']:
                ocr_partial_correct += 1
            if match_result['milvus_match']:
                milvus_correct += 1

            # ê²°ê³¼ ì €ì¥
            result_entry = {
                'image': image_path.name,
                'shape_idx': idx,
                'ground_truth': ground_truth,
                'predicted': predicted_text,
                'ocr_exact': match_result['ocr_exact_match'],
                'ocr_partial': match_result['ocr_partial_match'],
                'milvus_match': match_result['milvus_match'],
                'milvus_rank': match_result['milvus_rank'],
                'milvus_score': match_result['milvus_score'],
                'milvus_in_top_k': match_result['milvus_rank'] is not None and match_result['milvus_rank'] <= top_k,
                'top_search_results': match_result['top_results'],
            }
            detailed_results.append(result_entry)

            # ê°œë³„ ê²°ê³¼ ì¶œë ¥
            print(f"  [{total_shapes}] GT: {ground_truth}")
            print(f"        ì˜ˆì¸¡: {predicted_text}")
            print(f"        OCR ì •í™• ì¼ì¹˜: {'âœ…' if match_result['ocr_exact_match'] else 'âŒ'}")
            print(f"        OCR ë¶€ë¶„ ì¼ì¹˜: {'âœ…' if match_result['ocr_partial_match'] else 'âŒ'}")

            if match_result['milvus_match']:
                print(f"        Milvus ë§¤ì¹­: âœ… (ìˆœìœ„: {match_result['milvus_rank']}, ì ìˆ˜: {match_result['milvus_score']:.4f})")
                print(f"        Top-{top_k} í¬í•¨: {'âœ…' if match_result['milvus_rank'] <= top_k else 'âŒ'}")
            else:
                print(f"        Milvus ë§¤ì¹­: âŒ")

            # Top ê²€ìƒ‰ ê²°ê³¼ ì¶œë ¥
            if match_result['top_results']:
                print(f"        Top-{len(match_result['top_results'])} ê²€ìƒ‰ ê²°ê³¼:")
                for res in match_result['top_results']:
                    match_marker = " âœ…" if res['is_match'] else ""
                    print(f"         {res['rank']}. {res['title']} (ì ìˆ˜: {res['score']:.4f}){match_marker}")

            print()

        # ì„ë² ë”© ì‹¤íŒ¨ê°€ ë„ˆë¬´ ë§ìœ¼ë©´ ì¤‘ë‹¨
        if failed_embeddings > max_failed_embeddings:
            break

    # ============================================================
    # 8. ìµœì¢… í†µê³„ ì¶œë ¥
    # ============================================================
    print("\n" + "="*80)
    print("ğŸ“Š ìµœì¢… í‰ê°€ ê²°ê³¼")
    print("="*80)
    if total_shapes == 0:
        print("\ní‰ê°€í•  ìƒ˜í”Œì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
        ocr_exact_acc = ocr_exact_correct / total_shapes * 100
        ocr_partial_acc = ocr_partial_correct / total_shapes * 100
        milvus_acc = milvus_correct / total_shapes * 100

        print(f"\nì´ ìƒ˜í”Œ ìˆ˜: {total_shapes}")
        print(f"ì„ë² ë”© ì‹¤íŒ¨: {failed_embeddings}íšŒ")
        print(f"\nOCR ì •í™•ë„:")
        print(f"  - ì •í™• ì¼ì¹˜ (Exact Match): {ocr_exact_correct}/{total_shapes} ({ocr_exact_acc:.2f}%)")
        print(f"  - ë¶€ë¶„ ì¼ì¹˜ (Partial Match): {ocr_partial_correct}/{total_shapes} ({ocr_partial_acc:.2f}%)")
        print(f"\nMilvus ë§¤ì¹­ ì„±ê³µë¥  (Recall@{top_k}):")
        print(f"  - Top-{top_k} ë‚´ ì •ë‹µ í¬í•¨: {milvus_correct}/{total_shapes} ({milvus_acc:.2f}%)")
    print("="*80 + "\n")

    # ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ ì €ì¥
    result_file = gt_folder / "evaluation_results_v2.json"
    with open(result_file, 'w', encoding='utf-8') as f:
        json.dump({
            'summary': {
                'total_samples': total_shapes,
                'ocr_exact_correct': ocr_exact_correct,
                'ocr_partial_correct': ocr_partial_correct,
                'milvus_correct': milvus_correct,
                'failed_embeddings': failed_embeddings,
                'ocr_exact_accuracy': f"{ocr_exact_acc:.2f}%" if total_shapes else "N/A",
                'ocr_partial_accuracy': f"{ocr_partial_acc:.2f}%" if total_shapes else "N/A",
                f'milvus_recall_at_{top_k}': f"{milvus_acc:.2f}%" if total_shapes else "N/A",
                'top_k': top_k,
            },
            'detailed_results': detailed_results
        }, f, ensure_ascii=False, indent=2)

    print(f"âœ… ìƒì„¸ ê²°ê³¼ ì €ì¥: {result_file}")


# ============================================================
# 9. ë©”ì¸ í•¨ìˆ˜
# ============================================================
def main():
    parser = argparse.ArgumentParser(
        description='GT ë°ì´í„°ë¡œ OCR ë° Milvus ë§¤ì¹­ ì •í™•ë„ í‰ê°€ (OpenAI ì„ë² ë”© ì‚¬ìš©)'
    )

    # ê²½ë¡œ ê´€ë ¨ ì¸ì
    parser.add_argument('--gt-folder', type=str,
                        default='/opt/project/datasets/mmocr/GT',
                        help='GT í´ë” ê²½ë¡œ (ì´ë¯¸ì§€ ë° JSON íŒŒì¼ í¬í•¨)')

    # MMOCR ê´€ë ¨ ì¸ì
    parser.add_argument('--config', type=str,
                        default='/opt/project/datasets/mmocr/work_dirs/SATRN_original_size/satrn_shallow_5e_st_mj_aladin_original_size.py',
                        help='MMOCR ì„¤ì • íŒŒì¼ ê²½ë¡œ (*.py)')
    parser.add_argument('--checkpoint', type=str,
                        default='/opt/project/datasets/mmocr/work_dirs/SATRN_original_size_/epoch_14.pth',
                        help='MMOCR ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ê²½ë¡œ (*.pth)')
    parser.add_argument('--device', type=str, default='cuda:0',
                        help='ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤ (e.g., cuda:0, cpu)')

    # OpenAI ê´€ë ¨ ì¸ì
    parser.add_argument('--openai-api-key', type=str, default=None,
                        help='OpenAI API í‚¤ (ê¸°ë³¸ê°’: OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜)')
    parser.add_argument('--embedding-model', type=str, default='text-embedding-3-large',
                        help='OpenAI ì„ë² ë”© ëª¨ë¸')

    # Milvus ê´€ë ¨ ì¸ì
    parser.add_argument('--collection', type=str,
                        default='domestic_book_meta_embedding',
                        help='Milvus ì»¬ë ‰ì…˜ ì´ë¦„')
    parser.add_argument('--milvus-uri', type=str,
                        default='http://10.10.13.129:19530',
                        help='Milvus ì„œë²„ URI')
    parser.add_argument('--search-field', type=str,
                        default='itemTitle_embedding',
                        choices=['itemTitle_embedding', 'authorName_embedding'],
                        help='ê²€ìƒ‰í•  ì„ë² ë”© í•„ë“œ')
    parser.add_argument('--top-k', type=int, default=5,
                        help='Milvus Top-K ê²€ìƒ‰')

    # ê¸°íƒ€ ì˜µì…˜
    parser.add_argument('--temp-dir', type=str, default=None,
                        help='í¬ë¡­ëœ ì´ë¯¸ì§€ ì„ì‹œ ì €ì¥ ê²½ë¡œ (ê¸°ë³¸ê°’: GTí´ë”/temp_crops)')
    parser.add_argument('--auto-confirm', action='store_true',
                        help='API ë¹„ìš© í™•ì¸ í”„ë¡¬í”„íŠ¸ ê±´ë„ˆë›°ê¸°')
    parser.add_argument('--max-api-cost', type=float, default=1.0,
                        help='ìµœëŒ€ í—ˆìš© API ë¹„ìš© (USD)')

    args = parser.parse_args()

    # ê²½ë¡œ í™•ì¸
    gt_folder = Path(args.gt_folder).resolve()
    cfg_path = Path(args.config).resolve()
    ckpt_path = Path(args.checkpoint).resolve()

    if not gt_folder.is_dir():
        sys.exit(f'âŒ GT í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•Šê±°ë‚˜ ë””ë ‰í† ë¦¬ê°€ ì•„ë‹™ë‹ˆë‹¤: {gt_folder}')
    if not cfg_path.is_file():
        sys.exit(f'âŒ ì„¤ì • íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•Šê±°ë‚˜ íŒŒì¼ì´ ì•„ë‹™ë‹ˆë‹¤: {cfg_path}')
    if not ckpt_path.is_file():
        sys.exit(f'âŒ ì²´í¬í¬ì¸íŠ¸ê°€ ì¡´ì¬í•˜ì§€ ì•Šê±°ë‚˜ íŒŒì¼ì´ ì•„ë‹™ë‹ˆë‹¤: {ckpt_path}')

    # ì„ì‹œ í´ë” ê²½ë¡œ ì„¤ì •
    temp_dir = Path(args.temp_dir).resolve() if args.temp_dir else gt_folder / "temp_crops"

    # GPU ì„¤ì •
    device = args.device
    if 'cuda' in device:
        if not torch.cuda.is_available():
            print('âš ï¸ CUDAë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CPUë¡œ ì „í™˜í•©ë‹ˆë‹¤.')
            device = 'cpu'
        else:
            try:
                gpu_id = int(device.split(':')[-1])
                if gpu_id >= torch.cuda.device_count():
                     print(f'âš ï¸ ì§€ì •ëœ GPU ID({gpu_id})ê°€ ì‚¬ìš© ê°€ëŠ¥í•œ GPU ìˆ˜({torch.cuda.device_count()})ë³´ë‹¤ í½ë‹ˆë‹¤. cuda:0ìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.')
                     device = 'cuda:0'
            except (ValueError, IndexError):
                 print(f'âš ï¸ ì˜ëª»ëœ device í˜•ì‹ì…ë‹ˆë‹¤ ({device}). cuda:0ìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.')
                 device = 'cuda:0'

    print("\n" + "="*80)
    print("ğŸ“– GT ë°ì´í„° í‰ê°€ ì‹œìŠ¤í…œ (OpenAI ì„ë² ë”©)")
    print("="*80)
    print(f"\nì„¤ì •:")
    print(f"  - GT í´ë”: {gt_folder}")
    print(f"  - MMOCR ì„¤ì •: {cfg_path.name}")
    print(f"  - MMOCR ì²´í¬í¬ì¸íŠ¸: {ckpt_path.name}")
    print(f"  - ë””ë°”ì´ìŠ¤: {device}")
    print(f"  - OpenAI ì„ë² ë”© ëª¨ë¸: {args.embedding_model}")
    print(f"  - Milvus URI: {args.milvus_uri}")
    print(f"  - Milvus ì»¬ë ‰ì…˜: {args.collection}")
    print(f"  - Milvus ê²€ìƒ‰ í•„ë“œ: {args.search_field}")
    print(f"  - Milvus Top-K: {args.top_k}")
    print(f"  - ì„ì‹œ í´ë”: {temp_dir}")
    print(f"  - ìµœëŒ€ API ë¹„ìš©: ${args.max_api_cost:.2f}")

    # OpenAI ì„ë² ë” ì´ˆê¸°í™”
    print(f"\nğŸ”§ OpenAI ì„ë² ë” ì´ˆê¸°í™” ì¤‘...")
    try:
        embedder = OpenAIEmbedder(api_key=args.openai_api_key, model=args.embedding_model)
        print(f"âœ… OpenAI ì„ë² ë” ì´ˆê¸°í™” ì™„ë£Œ!")
    except Exception as e:
        sys.exit(f"âŒ OpenAI ì„ë² ë” ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

    # ëª¨ë¸ ë¡œë“œ
    print(f"\nğŸ”§ MMOCR ëª¨ë¸ ë¡œë”© ì¤‘...")
    model, pipeline_cfg = build_model_and_pipeline(cfg_path, ckpt_path, device)
    print(f"âœ… MMOCR ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")

    # í‰ê°€ ì‹œì‘
    evaluate_gt_data(
        gt_folder=gt_folder,
        model=model,
        pipeline_cfg=pipeline_cfg,
        embedder=embedder,
        milvus_collection=args.collection,
        milvus_uri=args.milvus_uri,
        search_field=args.search_field,
        top_k=args.top_k,
        temp_dir=temp_dir,
        auto_confirm=args.auto_confirm,
        max_api_cost=args.max_api_cost
    )

if __name__ == '__main__':
    main()