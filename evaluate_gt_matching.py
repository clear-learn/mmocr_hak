#!/usr/bin/env python
# ==========================================================
#  evaluate_gt_matching.py - GT ë°ì´í„°ë¡œ ì¶”ë¡  ì •í™•ë„ í‰ê°€
# ==========================================================
"""
GT í´ë”ì˜ ì´ë¯¸ì§€ì™€ JSONì„ ì‚¬ìš©í•˜ì—¬:
1. JSONì—ì„œ ì¢Œí‘œë¡œ ì´ë¯¸ì§€ í¬ë¡­
2. í¬ë¡­ëœ ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ë¡  (MMOCR íŒŒì´í”„ë¼ì¸ ì‚¬ìš©)
3. Milvusì—ì„œ ìœ ì‚¬ ì±… ê²€ìƒ‰
4. ì¶”ë¡  ê²°ê³¼ì™€ GT labelì„ ë¹„êµí•˜ì—¬ ì •í™•ë„ í‰ê°€
"""
import argparse
import json
from pathlib import Path
import sys
import torch
import numpy as np
from PIL import Image
from typing import List, Dict, Tuple
from mmengine.config import Config
from mmengine.runner import load_checkpoint
from mmengine.registry import init_default_scope, MODELS
from mmocr.utils import register_all_modules
from pymilvus import MilvusClient
import re # re ì„í¬íŠ¸ ìƒë‹¨ìœ¼ë¡œ ì´ë™

# Compose import (êµ¬ë²„ì „ ìš°ì„ )
try:
    from mmocr.datasets.pipelines.compose import Compose
except ImportError:
    from mmcv.transforms import Compose


# ============================================================
# 1. ì´ë¯¸ì§€ í¬ë¡­ ê´€ë ¨
# ============================================================
def get_bbox_from_points(points: List[List[float]]) -> Tuple[int, int, int, int]:
    """
    pointsì—ì„œ bounding box ì¢Œí‘œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    rectangleì€ 2ê°œ í¬ì¸íŠ¸, polygonì€ 4ê°œ í¬ì¸íŠ¸

    Returns:
        (x_min, y_min, x_max, y_max)
    """
    points_array = np.array(points)
    x_min = int(points_array[:, 0].min())
    y_min = int(points_array[:, 1].min())
    x_max = int(points_array[:, 0].max())
    y_max = int(points_array[:, 1].max())

    return x_min, y_min, x_max, y_max


def crop_image_from_shape(image_path: Path, shape: Dict, padding: int = 5) -> Image.Image:
    """
    JSON shape ì •ë³´ë¡œ ì´ë¯¸ì§€ë¥¼ í¬ë¡­í•©ë‹ˆë‹¤. (ì›ë³¸ ì‚¬ì´ì¦ˆ ìœ ì§€)

    Args:
        image_path: ì´ë¯¸ì§€ ê²½ë¡œ
        shape: shape ì •ë³´ (ì¢Œí‘œ í¬í•¨)
        padding: í¬ë¡­ ì˜ì—­ ì£¼ë³€ì— ì¶”ê°€í•  íŒ¨ë”© (í”½ì…€)
    """
    try:
        img = Image.open(image_path)
        img_width, img_height = img.size

        x_min, y_min, x_max, y_max = get_bbox_from_points(shape['points'])

        # íŒ¨ë”© ì¶”ê°€ (ì´ë¯¸ì§€ ê²½ê³„ë¥¼ ë²—ì–´ë‚˜ì§€ ì•Šë„ë¡)
        x_min = max(0, x_min - padding)
        y_min = max(0, y_min - padding)
        x_max = min(img_width, x_max + padding)
        y_max = min(img_height, y_max + padding)

        # ì´ë¯¸ì§€ í¬ë¡­ (ì›ë³¸ ì‚¬ì´ì¦ˆ)
        cropped = img.crop((x_min, y_min, x_max, y_max))
        return cropped
    except Exception as e:
        print(f"âš ï¸ ì´ë¯¸ì§€ í¬ë¡­ ì˜¤ë¥˜ ({image_path.name}): {e}")
        return None

# ============================================================
# 2. MMOCR ëª¨ë¸ ë¡œë“œ ë° ì¶”ë¡ 
# ============================================================
def build_model_and_pipeline(cfg_path: Path,
                             ckpt_path: Path,
                             device: str = 'cpu'):
    """MMOCR ëª¨ë¸ê³¼ ì¶”ë¡  íŒŒì´í”„ë¼ì¸ ì„¤ì •ì„ ë¹Œë“œí•©ë‹ˆë‹¤."""
    try:
        cfg = Config.fromfile(str(cfg_path))

        # pretrained / init_cfg ì œê±°
        for k in ('pretrained', 'init_cfg'):
            cfg.model.pop(k, None)
            if isinstance(cfg.model.get('backbone'), dict):
                cfg.model.backbone.pop(k, None)

        # ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì´ˆê¸°í™”
        init_default_scope(cfg.default_scope)
        register_all_modules()

        # ëª¨ë¸ ìƒì„± + checkpoint ë¡œë“œ
        model = MODELS.build(cfg.model)
        load_checkpoint(model, str(ckpt_path), map_location=device)
        model.to(device).eval()

        # inference ì „ìš© íŒŒì´í”„ë¼ì¸ ì„¤ì • ê°€ì ¸ì˜¤ê¸°
        orig_pipeline = (cfg.get('test_pipeline')
                         or cfg.test_dataloader.dataset.pipeline)

        # annotationì„ ìš”êµ¬í•˜ëŠ” ë³€í™˜ ì œê±°
        inference_pipeline_cfg = [
            t for t in orig_pipeline
            if 'Annotation' not in t['type'] and 'Label' not in t['type']
        ]

        # (!!!) ì¤‘ìš”: íŒŒì´í”„ë¼ì¸ ì„¤ì • ìì²´ë¥¼ ë°˜í™˜ (Compose ê°ì²´ X)
        return model, inference_pipeline_cfg
    except Exception as e:
        sys.exit(f"âŒ ëª¨ë¸ ë˜ëŠ” íŒŒì´í”„ë¼ì¸ ë¹Œë“œ ì‹¤íŒ¨: {e}")


@torch.inference_mode()
def infer_text_from_image(model, pipeline_cfg: List[Dict], img_path: Path) -> str:
    """
    ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ë°›ì•„ MMOCR íŒŒì´í”„ë¼ì¸ì„ ì ìš©í•˜ê³  í…ìŠ¤íŠ¸ë¥¼ ì¶”ë¡ í•©ë‹ˆë‹¤.
    pipeline_cfgëŠ” Compose ê°ì²´ê°€ ì•„ë‹Œ ì„¤ì • ë¦¬ìŠ¤íŠ¸ì—¬ì•¼ í•©ë‹ˆë‹¤.
    """
    try:
        # (!!!) ìˆ˜ì •: Compose ê°ì²´ë¥¼ í•¨ìˆ˜ ë‚´ì—ì„œ ìƒì„±
        pipeline = Compose(pipeline_cfg)
        # ì´ë¯¸ì§€ ê²½ë¡œë§Œ ì „ë‹¬, íŒŒì´í”„ë¼ì¸ì´ LoadImageFromFileë¶€í„° ì²˜ë¦¬
        data = dict(img_path=str(img_path), img_shape=Image.open(img_path).size[::-1]) # img_shape ì¶”ê°€ (ConditionApplyìš©)
        data = pipeline(data)

        # ë°°ì¹˜ í˜•íƒœë¡œ ê°ì‹¸ê¸°
        # MMOCR ìµœì‹  ë²„ì „ í˜¸í™˜ì„±ì„ ìœ„í•´ `inputs` ëŒ€ì‹  `imgs` ì‚¬ìš© ê³ ë ¤
        # (ë‹¨, ì‚¬ìš© ì¤‘ì¸ ë²„ì „ì— ë”°ë¼ inputsê°€ ë§ì„ ìˆ˜ ìˆìŒ)
        inputs_key = 'imgs' if 'imgs' in data else 'inputs'
        batch_data = {
            inputs_key: [data[inputs_key]],
            'data_samples': [data['data_samples']]
        }

        pred_sample = model.test_step(batch_data)[0]

        # pred_text ì¶”ì¶œ (ì—¬ëŸ¬ ê°€ëŠ¥í•œ í˜•ì‹ ì²˜ë¦¬)
        pred_text_obj = pred_sample.pred_text

        # MMOCR ë²„ì „ì— ë”°ë¥¸ pred_text ì¶”ì¶œ ë°©ì‹ ë¶„ê¸°
        if hasattr(pred_text_obj, 'item'): # ì˜ˆ: LabelData ê°ì²´
             pred_text = pred_text_obj.item
        elif isinstance(pred_text_obj, dict) and 'text' in pred_text_obj: # ì˜ˆ: {'text': '...', 'score': ...} í˜•íƒœ
             pred_text = pred_text_obj['text']
        elif isinstance(pred_text_obj, str):
             pred_text = pred_text_obj
        else: # ê¸°íƒ€ ê²½ìš° (ì˜ˆìƒì¹˜ ëª»í•œ í˜•ì‹)
             pred_text = str(pred_text_obj)

        # OCR ê²°ê³¼ í›„ì²˜ë¦¬ (evaluate_openai.pyì™€ ë™ì¼í•œ ë¡œì§)
        pred_text = normalize_text_for_ocr(parse_item_text(pred_text))

        return pred_text
    except FileNotFoundError:
        print(f"    âš ï¸ OCR ì˜¤ë¥˜: íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ - {img_path}")
        return ""
    except Exception as e:
        print(f"    âš ï¸ OCR ì¶”ë¡  ì¤‘ ì˜ˆì™¸ ë°œìƒ ({img_path.name}): {e}")
        # traceback.print_exc() # ìƒì„¸ ì—ëŸ¬ í™•ì¸ í•„ìš” ì‹œ ì£¼ì„ í•´ì œ
        return ""


# ============================================================
# 3. Milvus ê²€ìƒ‰ (ë³€ê²½ ì—†ìŒ)
# ============================================================
def search_in_milvus(
    query_text: str,
    collection_name: str = "domestic_book_meta_embedding",
    milvus_uri: str = "http://10.10.13.129:19530",
    search_field: str = "itemTitle_embedding",
    limit: int = 5
):
    """Milvusì—ì„œ ìœ ì‚¬ë„ ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
    # Milvus ê²€ìƒ‰ì€ ì¶”ë¡  í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìœ¼ë©´ ì˜ë¯¸ê°€ ì—†ìœ¼ë¯€ë¡œ ì²´í¬
    if not query_text:
        print("    âš ï¸ Milvus ê²€ìƒ‰ ê±´ë„ˆëœ€ (OCR ê²°ê³¼ ì—†ìŒ)")
        return None
    try:
        client = MilvusClient(uri=milvus_uri)

        results = client.search(
            collection_name=collection_name,
            data=[query_text], # ì„ë² ë”© ëª¨ë¸ì´ ë‚´ì¥ë˜ì–´ ìˆì§€ ì•Šìœ¼ë¯€ë¡œ í…ìŠ¤íŠ¸ ì§ì ‘ ì „ë‹¬
            anns_field=search_field,
            limit=limit,
            output_fields=[
                "itemId",
                "itemTitle",
                "itemSubTitle",
                "authorName",
            ]
        )
        # ê²°ê³¼ êµ¬ì¡° í™•ì¸ (ê²°ê³¼ê°€ ì—†ì„ ìˆ˜ ìˆìŒ)
        if results and results[0]:
             # score ëŒ€ì‹  distance ì‚¬ìš© í™•ì¸
             if isinstance(results[0][0].get('score'), float):
                  dist_key = 'score'
             else:
                  dist_key = 'distance'

             # entity êµ¬ì¡° í™•ì¸
             if 'entity' in results[0][0]:
                  entity_key = 'entity'
             else:
                  entity_key = None # entity ì—†ì´ ë°”ë¡œ í•„ë“œë“¤ì´ ë‚˜ì˜¬ ê²½ìš°

             parsed_results = []
             for hit in results[0]:
                  entity_data = hit.get(entity_key) if entity_key else hit
                  parsed_results.append({
                       'id': hit['id'],
                       'distance': float(hit[dist_key]),
                       'entity': entity_data if entity_data else {}
                  })
             return [parsed_results] # ì›ë³¸ í•¨ìˆ˜ì™€ ë™ì¼í•œ í˜•íƒœë¡œ ë°˜í™˜ [[]]
        else:
             return None # ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ

    except Exception as e:
        print(f"    âš ï¸ Milvus ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        return None

# ============================================================
# 4. OCR ê²°ê³¼ í›„ì²˜ë¦¬ (evaluate_openai.pyì™€ ë™ì¼)
# ============================================================
def parse_item_text(text_str):
    """Parse dict-string format: "{'item': 'text', 'score': [...]}" """
    text_str = str(text_str)
    if text_str.startswith('{') and "'item':" in text_str:
        try:
            import ast
            parsed = ast.literal_eval(text_str)
            if isinstance(parsed, dict) and 'item' in parsed:
                return str(parsed['item'])
        except:
            pass
    return text_str


def normalize_text_for_ocr(text_str):
    """Remove special tokens and normalize whitespace for OCR output."""
    import re
    text_str = str(text_str)

    # Remove special tokens
    special_tokens = ['<UNK>', '<BOS>', '<EOS>', '<PAD>', '<unk>', '<bos>', '<eos>', '<pad>']
    for token in special_tokens:
        text_str = text_str.replace(token, ' ')

    # Normalize whitespace
    text_str = re.sub(r'\s+', ' ', text_str).strip()

    return text_str


# ============================================================
# 5. í‰ê°€ìš© í…ìŠ¤íŠ¸ ì •ê·œí™” (ë³€ê²½ ì—†ìŒ)
# ============================================================
def normalize_text(text: str) -> str:
    """í…ìŠ¤íŠ¸ ì •ê·œí™” (ê³µë°±, íŠ¹ìˆ˜ë¬¸ì ì œê±°) - í‰ê°€ìš©"""
    # ê³µë°± ì œê±°
    text = re.sub(r'\s+', '', text)
    # ì¶”ê°€: ê¸°ë³¸ì ì¸ íŠ¹ìˆ˜ë¬¸ì ì œê±° (ì˜µì…˜)
    # text = re.sub(r'[^\w]', '', text) # ì•ŒíŒŒë²³, ìˆ«ì, ë°‘ì¤„(_)ë§Œ ë‚¨ê¹€
    return text.lower()


def check_match(predicted: str, ground_truth: str, top_results: list) -> Dict:
    """
    ì˜ˆì¸¡ ê²°ê³¼ì™€ GTë¥¼ ë¹„êµí•˜ê³ , Milvus ê²€ìƒ‰ ê²°ê³¼ë„ í‰ê°€í•©ë‹ˆë‹¤.
    """
    pred_norm = normalize_text(predicted)
    gt_norm = normalize_text(ground_truth)

    # OCR ì •í™•ë„
    ocr_exact_match = (pred_norm == gt_norm)
    # ë¶€ë¶„ ì¼ì¹˜ ì¡°ê±´ ì™„í™”: GTê°€ ì˜ˆì¸¡ê°’ ì•ˆì— í¬í•¨ë˜ëŠ”ì§€ë§Œ í™•ì¸
    # (ì˜ˆ: ì˜ˆì¸¡='í† ì§€1ê¶Œ', GT='í† ì§€' -> ë¶€ë¶„ ì¼ì¹˜ O)
    ocr_partial_match = (gt_norm in pred_norm) if pred_norm else False # ì˜ˆì¸¡ê°’ì´ ë¹„ì–´ìˆìœ¼ë©´ ë¶€ë¶„ì¼ì¹˜ X

    # Milvus ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì •ë‹µ ì°¾ê¸°
    milvus_match = False
    milvus_rank = None
    milvus_score = None
    search_results_info = []

    if top_results and top_results[0]:
        for rank, hit in enumerate(top_results[0], 1):
            entity = hit.get('entity', {}) # entityê°€ ì—†ì„ ê²½ìš° ëŒ€ë¹„
            distance = hit.get('distance') # score/distance í†µì¼
            title = entity.get('itemTitle', '')
            title_norm = normalize_text(title)

            is_match = (gt_norm in title_norm) if title_norm else False

            # ê²€ìƒ‰ ê²°ê³¼ ì •ë³´ ì €ì¥
            search_results_info.append({
                'rank': rank,
                'title': title,
                'score': distance, # score/distance í†µì¼
                'is_match': is_match
            })

            # ì •ë‹µê³¼ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸ (ì´ë¯¸ ë§¤ì¹­ëœ ê²½ìš° ìˆœìœ„ë§Œ ê¸°ë¡)
            if is_match and not milvus_match:
                milvus_match = True
                milvus_rank = rank
                milvus_score = distance

    return {
        'ocr_exact_match': ocr_exact_match,
        'ocr_partial_match': ocr_partial_match,
        'milvus_match': milvus_match,
        'milvus_rank': milvus_rank,
        'milvus_score': milvus_score,
        'top_results': search_results_info,
    }


# ============================================================
# 6. ë©”ì¸ í‰ê°€ í•¨ìˆ˜ (ìˆ˜ì •ë¨)
# ============================================================
def evaluate_gt_data(
    gt_folder: Path,
    model,
    pipeline_cfg: List[Dict], # (!!!) ìˆ˜ì •: Compose ê°ì²´ ëŒ€ì‹  ì„¤ì • ë¦¬ìŠ¤íŠ¸ ë°›ìŒ
    milvus_collection: str,
    milvus_uri: str,
    search_field: str,
    top_k: int = 5,
    temp_dir: Path = None
):
    """
    GT í´ë”ì˜ ëª¨ë“  ë°ì´í„°ë¥¼ í‰ê°€í•©ë‹ˆë‹¤.
    ì´ë¯¸ì§€ ì²˜ë¦¬ëŠ” infer_text_from_image ë‚´ë¶€ì˜ íŒŒì´í”„ë¼ì¸ì— ë§¡ê¹ë‹ˆë‹¤.
    """

    if temp_dir is None:
        temp_dir = gt_folder / "temp_crops"
    temp_dir.mkdir(exist_ok=True)

    # JSON íŒŒì¼ ëª©ë¡
    json_files = sorted(gt_folder.glob("*.json"))

    if not json_files:
        print("âŒ JSON íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    print(f"ğŸ“Š ì´ {len(json_files)}ê°œì˜ ì´ë¯¸ì§€ í‰ê°€ ì‹œì‘ (MMOCR íŒŒì´í”„ë¼ì¸ ì ìš©)\n") # ë¡œê·¸ ìˆ˜ì •

    total_shapes = 0
    ocr_exact_correct = 0
    ocr_partial_correct = 0
    milvus_correct = 0

    detailed_results = []

    for json_file in json_files:
        # JSON ë¡œë“œ
        try:
            with open(json_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
        except json.JSONDecodeError:
            print(f"âš ï¸ JSON íŒŒì‹± ì˜¤ë¥˜: {json_file.name}")
            continue
        except Exception as e:
            print(f"âš ï¸ JSON ë¡œë“œ ì˜¤ë¥˜ ({json_file.name}): {e}")
            continue

        # ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
        image_path = gt_folder / data.get('imagePath', '') # í‚¤ ì¡´ì¬ í™•ì¸
        if not data.get('imagePath') or not image_path.exists():
            print(f"âš ï¸ ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ ëˆ„ë½ ë˜ëŠ” íŒŒì¼ ì—†ìŒ: {image_path}")
            continue

        print(f"\n{'='*80}")
        print(f"ğŸ“· ì²˜ë¦¬ ì¤‘: {image_path.name}")
        print(f"{'='*80}\n")

        # ê° shape ì²˜ë¦¬
        shapes = data.get('shapes', [])
        if not shapes:
            print(f"    âš ï¸ 'shapes' ì •ë³´ ì—†ìŒ: {json_file.name}")
            continue

        for idx, shape in enumerate(shapes):
            ground_truth = shape.get('label')
            if not ground_truth:
                print(f"    âš ï¸ shape {idx}: 'label' ì •ë³´ ì—†ìŒ")
                continue

            total_shapes += 1

            # 1. ì´ë¯¸ì§€ í¬ë¡­ (íŒ¨ë”© í¬í•¨, ì›ë³¸ í•´ìƒë„ ìœ ì§€)
            cropped_img = crop_image_from_shape(image_path, shape)
            if cropped_img is None:
                continue # í¬ë¡­ ì‹¤íŒ¨ ì‹œ ë‹¤ìŒ shapeìœ¼ë¡œ

            # 2. í¬ë¡­ëœ ì´ë¯¸ì§€ë¥¼ ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥ (MMOCR íŒŒì´í”„ë¼ì¸ ì…ë ¥ìš©)
            crop_path = temp_dir / f"{image_path.stem}_{idx}.jpg"
            try:
                # RGBA -> RGB ë³€í™˜ (ì €ì¥ ì „)
                if cropped_img.mode == 'RGBA':
                    background = Image.new('RGB', cropped_img.size, (255, 255, 255))
                    background.paste(cropped_img, mask=cropped_img.split()[3])
                    cropped_img = background
                elif cropped_img.mode != 'RGB':
                    cropped_img = cropped_img.convert('RGB')

                cropped_img.save(crop_path)
            except Exception as e:
                 print(f"    âš ï¸ ì„ì‹œ íŒŒì¼ ì €ì¥ ì˜¤ë¥˜ ({crop_path.name}): {e}")
                 continue # ì´ shape ì²˜ë¦¬ ë¶ˆê°€

            # (!!!) ì œê±°: ìˆ˜ë™ íšŒì „ ë° ë¦¬ì‚¬ì´ì¦ˆ ë¡œì§ ì‚­ì œë¨

            # í¬ë¡­ëœ ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸° ì •ë³´ ì¶œë ¥ (ë””ë²„ê¹…ìš©)
            if total_shapes <= 3:  # ì²˜ìŒ 3ê°œë§Œ ìƒì„¸ ì •ë³´ ì¶œë ¥
                print(f"      [DEBUG] í¬ë¡­ëœ ì›ë³¸ ì´ë¯¸ì§€: {crop_path.name}, í¬ê¸°: {cropped_img.size}")

            # 3. OCR ì¶”ë¡  (MMOCR íŒŒì´í”„ë¼ì¸ì´ íšŒì „/ë¦¬ì‚¬ì´ì¦ˆ ì²˜ë¦¬)
            predicted_text = infer_text_from_image(model, pipeline_cfg, crop_path)

            # 4. Milvus ê²€ìƒ‰
            search_results = search_in_milvus(
                predicted_text,
                collection_name=milvus_collection,
                milvus_uri=milvus_uri,
                search_field=search_field,
                limit=top_k
            )

            # 5. ì •í™•ë„ í‰ê°€
            match_result = check_match(predicted_text, ground_truth, search_results)

            # í†µê³„ ì—…ë°ì´íŠ¸
            if match_result['ocr_exact_match']:
                ocr_exact_correct += 1
            if match_result['ocr_partial_match']:
                ocr_partial_correct += 1
            if match_result['milvus_match']:
                milvus_correct += 1

            # ê²°ê³¼ ì €ì¥
            result_entry = {
                'image': image_path.name,
                'shape_idx': idx,
                'ground_truth': ground_truth,
                'predicted': predicted_text,
                'ocr_exact': match_result['ocr_exact_match'],
                'ocr_partial': match_result['ocr_partial_match'],
                'milvus_match': match_result['milvus_match'],
                'milvus_rank': match_result['milvus_rank'],
                'milvus_score': match_result['milvus_score'],
                'milvus_in_top_k': match_result['milvus_rank'] is not None and match_result['milvus_rank'] <= top_k, # top-k ì‚¬ìš©
                'top_search_results': match_result['top_results'],
                # 'ocr_input_size': cropped_img.size, # ì‚­ì œ ë˜ëŠ” íŒŒì´í”„ë¼ì¸ í›„ í¬ê¸° ê¸°ë¡ í•„ìš” ì‹œ ìˆ˜ì •
            }
            detailed_results.append(result_entry)

            # ê°œë³„ ê²°ê³¼ ì¶œë ¥
            print(f"  [{total_shapes}] GT: {ground_truth}")
            print(f"        ì˜ˆì¸¡: {predicted_text}")
            print(f"        OCR ì •í™• ì¼ì¹˜: {'âœ…' if match_result['ocr_exact_match'] else 'âŒ'}")
            print(f"        OCR ë¶€ë¶„ ì¼ì¹˜: {'âœ…' if match_result['ocr_partial_match'] else 'âŒ'}")

            if match_result['milvus_match']:
                print(f"        Milvus ë§¤ì¹­: âœ… (ìˆœìœ„: {match_result['milvus_rank']}, ì ìˆ˜: {match_result['milvus_score']:.4f})")
                print(f"        Top-{top_k} í¬í•¨: {'âœ…' if match_result['milvus_rank'] <= top_k else 'âŒ'}")
            else:
                print(f"        Milvus ë§¤ì¹­: âŒ")

            # Top ê²€ìƒ‰ ê²°ê³¼ ì¶œë ¥
            if match_result['top_results']:
                print(f"        Top-{len(match_result['top_results'])} ê²€ìƒ‰ ê²°ê³¼:")
                for res in match_result['top_results']:
                    match_marker = " âœ…" if res['is_match'] else ""
                    print(f"         {res['rank']}. {res['title']} (ì ìˆ˜: {res['score']:.4f}){match_marker}")

            print()

    # ============================================================
    # 6. ìµœì¢… í†µê³„ ì¶œë ¥
    # ============================================================
    print("\n" + "="*80)
    print("ğŸ“Š ìµœì¢… í‰ê°€ ê²°ê³¼")
    print("="*80)
    if total_shapes == 0:
        print("\ní‰ê°€í•  ìƒ˜í”Œì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
        ocr_exact_acc = ocr_exact_correct / total_shapes * 100
        ocr_partial_acc = ocr_partial_correct / total_shapes * 100
        milvus_acc = milvus_correct / total_shapes * 100

        print(f"\nì´ ìƒ˜í”Œ ìˆ˜: {total_shapes}")
        print(f"\nOCR ì •í™•ë„:")
        print(f"  - ì •í™• ì¼ì¹˜ (Exact Match): {ocr_exact_correct}/{total_shapes} ({ocr_exact_acc:.2f}%)")
        print(f"  - ë¶€ë¶„ ì¼ì¹˜ (Partial Match): {ocr_partial_correct}/{total_shapes} ({ocr_partial_acc:.2f}%)")
        print(f"\nMilvus ë§¤ì¹­ ì„±ê³µë¥  (Recall@{top_k}):")
        print(f"  - Top-{top_k} ë‚´ ì •ë‹µ í¬í•¨: {milvus_correct}/{total_shapes} ({milvus_acc:.2f}%)")
    print("="*80 + "\n")

    # ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ ì €ì¥
    result_file = gt_folder / "evaluation_results.json"
    with open(result_file, 'w', encoding='utf-8') as f:
        json.dump({
            'summary': {
                'total_samples': total_shapes,
                'ocr_exact_correct': ocr_exact_correct,
                'ocr_partial_correct': ocr_partial_correct,
                'milvus_correct': milvus_correct,
                'ocr_exact_accuracy': f"{ocr_exact_acc:.2f}%" if total_shapes else "N/A",
                'ocr_partial_accuracy': f"{ocr_partial_acc:.2f}%" if total_shapes else "N/A",
                f'milvus_recall_at_{top_k}': f"{milvus_acc:.2f}%" if total_shapes else "N/A",
                'top_k': top_k,
                # 'target_height': target_height, # ì‚­ì œë¨
            },
            'detailed_results': detailed_results
        }, f, ensure_ascii=False, indent=2)

    print(f"âœ… ìƒì„¸ ê²°ê³¼ ì €ì¥: {result_file}")


# ============================================================
# 7. ë©”ì¸ í•¨ìˆ˜
# ============================================================
def main():
    parser = argparse.ArgumentParser(
        description='GT ë°ì´í„°ë¡œ OCR ë° Milvus ë§¤ì¹­ ì •í™•ë„ í‰ê°€'
    )

    # ê²½ë¡œ ê´€ë ¨ ì¸ì
    # (!!!) ìˆ˜ì •: required=True ì œê±°, default ê²½ë¡œ ì„¤ì •
    parser.add_argument('--gt-folder', type=str,
                        default='/opt/project/datasets/mmocr/GT', # ì˜ˆì‹œ ê¸°ë³¸ ê²½ë¡œ
                        help='GT í´ë” ê²½ë¡œ (ì´ë¯¸ì§€ ë° JSON íŒŒì¼ í¬í•¨)')

    # MMOCR ê´€ë ¨ ì¸ì
    # (!!!) ìˆ˜ì •: required=True ì œê±°, default ê²½ë¡œ ì„¤ì •
    parser.add_argument('--config', type=str,
                        default='/opt/project/datasets/mmocr/work_dirs/SATRN_original_size/satrn_shallow_5e_st_mj_aladin_original_size.py', # ì˜ˆì‹œ ê¸°ë³¸ ê²½ë¡œ
                        help='MMOCR ì„¤ì • íŒŒì¼ ê²½ë¡œ (*.py)')
    # (!!!) ìˆ˜ì •: required=True ì œê±°, default ê²½ë¡œ ì„¤ì •
    parser.add_argument('--checkpoint', type=str,
                        default='/opt/project/datasets/mmocr/work_dirs/SATRN_original_size_/epoch_14.pth', # ì˜ˆì‹œ ê¸°ë³¸ ê²½ë¡œ
                        help='MMOCR ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ê²½ë¡œ (*.pth)')
    parser.add_argument('--device', type=str, default='cuda:0',
                        help='ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤ (e.g., cuda:0, cpu)')

    # Milvus ê´€ë ¨ ì¸ì (ê¸°ì¡´ê³¼ ë™ì¼)
    parser.add_argument('--collection', type=str,
                        default='domestic_book_meta_embedding',
                        help='Milvus ì»¬ë ‰ì…˜ ì´ë¦„')
    parser.add_argument('--milvus-uri', type=str,
                        default='http://10.10.13.129:19530', # ê¸°ë³¸ê°’ ìœ ì§€ ë˜ëŠ” ë³€ê²½
                        help='Milvus ì„œë²„ URI')
    parser.add_argument('--search-field', type=str,
                        default='itemTitle_embedding',
                        choices=['itemTitle_embedding', 'authorName_embedding'],
                        help='ê²€ìƒ‰í•  ì„ë² ë”© í•„ë“œ')
    parser.add_argument('--top-k', type=int, default=5,
                        help='Milvus Top-K ê²€ìƒ‰')
    parser.add_argument('--temp-dir', type=str, default=None,
                        help='í¬ë¡­ëœ ì´ë¯¸ì§€ ì„ì‹œ ì €ì¥ ê²½ë¡œ (ê¸°ë³¸ê°’: GTí´ë”/temp_crops)')

    args = parser.parse_args()

    # ê²½ë¡œ í™•ì¸ (ì´ì œ default ê°’ì´ ìˆìœ¼ë¯€ë¡œ ì¡´ì¬ ì—¬ë¶€ë§Œ í™•ì¸)
    gt_folder = Path(args.gt_folder).resolve()
    cfg_path = Path(args.config).resolve()
    ckpt_path = Path(args.checkpoint).resolve()

    if not gt_folder.is_dir():
        sys.exit(f'âŒ GT í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•Šê±°ë‚˜ ë””ë ‰í† ë¦¬ê°€ ì•„ë‹™ë‹ˆë‹¤: {gt_folder}')
    if not cfg_path.is_file():
        sys.exit(f'âŒ ì„¤ì • íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•Šê±°ë‚˜ íŒŒì¼ì´ ì•„ë‹™ë‹ˆë‹¤: {cfg_path}')
    if not ckpt_path.is_file():
        sys.exit(f'âŒ ì²´í¬í¬ì¸íŠ¸ê°€ ì¡´ì¬í•˜ì§€ ì•Šê±°ë‚˜ íŒŒì¼ì´ ì•„ë‹™ë‹ˆë‹¤: {ckpt_path}')

    # ì„ì‹œ í´ë” ê²½ë¡œ ì„¤ì •
    temp_dir = Path(args.temp_dir).resolve() if args.temp_dir else gt_folder / "temp_crops"

    # GPU ì„¤ì •
    device = args.device
    if 'cuda' in device:
        if not torch.cuda.is_available():
            print('âš ï¸ CUDAë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CPUë¡œ ì „í™˜í•©ë‹ˆë‹¤.')
            device = 'cpu'
        else:
            try:
                gpu_id = int(device.split(':')[-1])
                if gpu_id >= torch.cuda.device_count():
                     print(f'âš ï¸ ì§€ì •ëœ GPU ID({gpu_id})ê°€ ì‚¬ìš© ê°€ëŠ¥í•œ GPU ìˆ˜({torch.cuda.device_count()})ë³´ë‹¤ í½ë‹ˆë‹¤. cuda:0ìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.')
                     device = 'cuda:0'
            except (ValueError, IndexError):
                 print(f'âš ï¸ ì˜ëª»ëœ device í˜•ì‹ì…ë‹ˆë‹¤ ({device}). cuda:0ìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.')
                 device = 'cuda:0'

    print("\n" + "="*80)
    print("ğŸ“– GT ë°ì´í„° í‰ê°€ ì‹œìŠ¤í…œ")
    print("="*80)
    print(f"\nì„¤ì •:")
    print(f"  - GT í´ë”: {gt_folder}")
    print(f"  - MMOCR ì„¤ì •: {cfg_path.name}")
    print(f"  - MMOCR ì²´í¬í¬ì¸íŠ¸: {ckpt_path.name}")
    print(f"  - ë””ë°”ì´ìŠ¤: {device}")
    print(f"  - Milvus URI: {args.milvus_uri}")
    print(f"  - Milvus ì»¬ë ‰ì…˜: {args.collection}")
    print(f"  - Milvus ê²€ìƒ‰ í•„ë“œ: {args.search_field}")
    print(f"  - Milvus Top-K: {args.top_k}")
    print(f"  - ì„ì‹œ í´ë”: {temp_dir}")

    # ëª¨ë¸ ë¡œë“œ
    print(f"\nğŸ”§ ëª¨ë¸ ë¡œë”© ì¤‘...")
    model, pipeline_cfg = build_model_and_pipeline(cfg_path, ckpt_path, device)
    print(f"âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")

    # í‰ê°€ ì‹œì‘
    evaluate_gt_data(
        gt_folder=gt_folder,
        model=model,
        pipeline_cfg=pipeline_cfg,
        milvus_collection=args.collection,
        milvus_uri=args.milvus_uri,
        search_field=args.search_field,
        top_k=args.top_k,
        temp_dir=temp_dir
    )

if __name__ == '__main__':
    main()